# Responsible-AI-Moderation Model 

## Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
- [Set Configuration Variables](#set-configuration-variables)
- [Models Required](#models-required)
- [Running the Application](#running-the-application)
- [License](#license)
- [Contact](#contact)
  
## Introduction
The **Moderation Model** module acts as a central hub for machine learning models for prompt injection, toxicity, jailbreak, restricted topic, custom theme and refusal checks. It provides the endpoints to utilize the response generated by these models.

## Features
The **Moderation Model** module acts as a wrapper for the traditional AI models we are using for various checks like prompt injection, jailbreak, toxicity etc. 

## Installation
To run the application, first we need to install Python and the necessary packages:

1. Install Python (version >= 3.9) from the [official website](https://www.python.org/downloads/) and ensure it is added to your system PATH.

2. Clone the repository : responsible-ai-mm-flask:
    ```sh
    git clone <repository-url>
    ```

3. Navigate to the `responsible-ai-mm-flask` directory:
    ```sh
    cd responsible-ai-mm-flask
    ```

4. Create a virtual environment:
    ```sh
    python -m venv venv
    ```

5. Activate the virtual environment:
    - On Windows:
        ```sh
        .\venv\Scripts\activate
         ```

6. Go to the `requirements` directory where the `requirement.txt` file is present and install the requirements:
    ```sh
    pip install -r requirement.txt
    ```

## Set Configuration Variables
After installing all the required packages, configure the variables necessary to run the APIs.

1. Navigate to the `src` directory:
    ```sh
    cd ..
    ```

2. Locate the `.env` file, which contains keys like the following:

  ```sh
  workers=1
  WORKERS="${workers}"
  # DB_NAME="${dbname}"
  # DB_USERNAME="${username}"
  # DB_PWD="${password}"
  # DB_IP="${ipaddress}"
  # DB_PORT="${port}"
  # MONGO_PATH="mongodb://${DB_USERNAME}:${DB_PWD}@${DB_IP}:${DB_PORT}/"
  # MONGO_PATH= "mongodb://localhost:27017/"
  ```

3. Replace the placeholders with your actual values.

## Models Required
The following models are required to run the application. Download all the model files from the links provided, and place it in the folder name provided.

1. Prompt Injection - [https://huggingface.co/deepset/deberta-v3-base-injection/tree/main](HuggingFace)
Name the folder as 'dbertaInjection'.
2. Sentence Encoding Model - [https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/tree/main](HuggingFace)
Name the folder as 'paraphrase-mpnet-base-v2'.
3. Restricted Topic - [https://huggingface.co/MoritzLaurer/deberta-v3-large-zeroshot-v2.0/tree/main](HuggingFace)
Name the folder as 'restricted-dberta-large-zeroshot'.
4. Sentence Transformer Model - [https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1/tree/main](HuggingFace)
Name the folder as 'multi-qa-mpnet-base-dot-v1'.
5. Detoxify - [https://huggingface.co/unitary/toxic-bert/tree/main](HuggingFace)
Name the folder as 'detoxify'.

Place the above folders in a folder named 'models' in the following way: 'responsible-ai-mm-flask-main/models'.

## Running the Application
Once we have completed all the aforementioned steps, we can start the service.

1. Navigate to the `src` directory:

2. Run `main.py` file:
    ```sh
    python main.py
     ```

3. Open the following URL in your browser:
   [http://localhost:8000/rai/v1/raimoderationmodels/docs](http://localhost:8000/rai/v1/raimoderationmodels/docs)


  
## License
The source code for the project is licensed under the MIT license, which you can find in the [LICENSE.txt](LICENSE.txt) file.

## Contact
If you have more questions or need further insights please feel free to connect with us @ Infosysraitoolkit@infosys.com



