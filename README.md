![image](https://github.com/user-attachments/assets/19fef8de-743b-482d-9ee9-9116364b4c2a)# Infosys-Responsible-AI-Toolkit
The Infosys Responsible AI toolkit incorporates various features including safety, privacy, security, explainability, fairness & bias and hallucination detection to ensure AI solutions are trustworthy and transparent. We are hosting our below API-based guardrails on platforms like Azure OpenAI.

To install any of the Infosys Responsible AI Toolkit modules, Open respective repositories & follow the instruction given in the readme file.
S.no  | Module name     |     |  Repository name  |
1.     Explainability API     responsible-ai-explainability,responsible-ai-llm-explain
2.     Fairness & Bias API    responsible-ai-fairness  
3.     Privacy API            responsible-ai-privacy
4.     Security API           responsible-ai-security-API
5.     Safety API             responsible-ai-safety
6.     Hallucination API      responsible-ai-hallucination
7.     ModerationLayer API    responsible-ai-moderationlayer,responsible-ai-moderationModel

If you have more questions or need further insights please feel free to connect with us  Infosysraitoolkit@infosys.com
