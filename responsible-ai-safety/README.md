# responsible-ai-safety

## Introduction
Safety is an application which detects and masks any unsafe or harmful content present in Unstructured text and inappropriate content in the image and video.
 
## Requirements
1. Python 3.9 - 3.11
2. VSCode
# Model 
 1. Detoxify model for Unstructured text.
 2. NFSW model for image : https://github.com/GantMan/nsfw_model
## Steps to run this module :
1. Clone this repository in vscode
2. Create a virtual environment for python using cmd -
   `python -m venv <env-name>`
3. Activate the python virtual environment and install all the dependencies in requirement.txt file of the     cloned repository -
   `pip install -r path/to/requirements.txt`
4. Open .env file in vscode and configure the entries in it
5. In the virtual environment go to src folder of cloned repository and run below command to run the module-
   `py main.py`
## Contact
If you have more questions or need further insights please feel free to connect with us @
Infosysraitoolkit@infosys.com
